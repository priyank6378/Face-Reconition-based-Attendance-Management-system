{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1c84d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7ea60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset():\n",
    "    base_dir = r\"E:\\semester 5\\mini project\\face recognition algorithms\\dataset\"\n",
    "    training_images_dir = [base_dir+'\\\\'+name for name in os.listdir(base_dir)]\n",
    "    names = {}\n",
    "    i = 0\n",
    "    for p in os.listdir(base_dir):\n",
    "        names[p] = i\n",
    "        i+=1\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    for person_dir in training_images_dir:\n",
    "        for img in os.listdir(person_dir):\n",
    "            image = cv2.imread(person_dir+'\\\\'+img)\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            image = cv2.resize(image, (200,200))\n",
    "            image = image/255\n",
    "            X.append(image)\n",
    "            y.append(names[person_dir.split('\\\\')[-1]])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X,y,names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13964264",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y,names = make_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeebe2ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31acf1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHAPE = (200,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426bf186",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(np.reshape(X, (X.shape[0], 40000)))\n",
    "plt.figure(figsize=(18, 7))\n",
    "plt.plot(pca.explained_variance_ratio_.cumsum(), lw=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c9cada",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(pca.explained_variance_ratio_.cumsum() > 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "569ba840",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(pca.components_[4].reshape((200,200)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21634e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=62)\n",
    "pca.fit(np.reshape(X, (X.shape[0], 40000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3948828d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pca.transform(np.reshape(X, (X.shape[0], 40000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b9d01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27e5fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(max_iter=500)\n",
    "classifier.fit(x_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392e158f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.score(x_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2de27bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_faces_from_image_2(img):\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector(gray_img)\n",
    "    cropped_faces = []\n",
    "    take = 7  # increase the size of the bounding box\n",
    "    for face in faces:\n",
    "        cropped_faces.append(img[ face.top()-take :face.bottom()+take, face.left()-take:face.right()+take , :].copy())\n",
    "    return cropped_faces\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33c15c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = r\"E:\\semester 5\\mini project\\face recognition algorithms\\Facenet\\test.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82427754",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(test_img)\n",
    "faces = get_faces_from_image_2(image)\n",
    "len(faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401b017a",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 11\n",
    "print(faces[index].shape)\n",
    "face = cv2.cvtColor(faces[index], cv2.COLOR_BGR2GRAY)\n",
    "face = cv2.resize(face, (200,200))\n",
    "face = face.reshape((40000))\n",
    "face = np.array([face])\n",
    "face = face/255\n",
    "face = pca.transform(face)\n",
    "plt.imshow(faces[index][:,:,::-1])\n",
    "print(face.dtype)\n",
    "prediction = classifier.predict(face)\n",
    "print([k for k,v in names.items() if v==prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472458b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699ea23a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d74903f3c0a8ddc14f9ca93275717badad87b72706d588d6160414d0927f0c5b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
